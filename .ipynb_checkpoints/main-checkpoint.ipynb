{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fee38a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Подключаем камеру\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 720) # Width\n",
    "cap.set(4, 1280) # Lenght\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "#Зацикливаем получение кадров от камеры\n",
    "flag = 0\n",
    "while True:\n",
    "    with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True,min_detection_confidence=0.5,\n",
    "                               min_tracking_confidence=0.5) as face_mesh:\n",
    "        \n",
    "        # Получение картинки с камеры\n",
    "        ret, image = cap.read()\n",
    "        \n",
    "        image.flags.writeable = False\n",
    "        # Меняем цветовую гамму\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Либа по посторойке координат на лице\n",
    "        results = face_mesh.process(image)\n",
    "        \n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Возвращаем цвет обратно\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        \n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(image=image,\n",
    "                    landmark_list=face_landmarks,\n",
    "                    connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                    landmark_drawing_spec=None,\n",
    "                    connection_drawing_spec=mp_drawing_styles\n",
    "                    .get_default_face_mesh_tesselation_style())\n",
    "\n",
    "        \n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime\n",
    "        cv2.putText(image, str(int(fps)),(10,30), cv2.FONT_HERSHEY_PLAIN, 2, (255,0,0), 2) # ФреймРейт\n",
    "\n",
    "        cv2.imshow('python', image)\n",
    "        \n",
    "        if cv2.waitKey(5) & 0xFF == 27: # exit on ESC\n",
    "            break\n",
    "        \n",
    "cv2.destroyWindow(\"python\")\n",
    "cap.release()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ff2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.multiply((1, 2 ,4), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61b0196a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1ecedc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH_1 = os.path.join('data', 'images')\n",
    "IMAGES_PATH_2 = os.path.join('data', 'edit_images')\n",
    "number_images = 30\n",
    "\n",
    "arr_cords_emotion = np.array([[\"name\", 'id', [('x', 'y', 'z')]]], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "75a83c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictMediapipeInArray(emotion_id, name, face_landmarks):\n",
    "    arr_cords = list()\n",
    "    for item in face_landmarks:\n",
    "        arr_cords.append((item.x, item.y, item.z))\n",
    "    \n",
    "    arr_cords_emotion = np.append(arr_cords_emotion, [[name, emotion_id, arr_cords]], axis = 0)\n",
    "    del arr_cords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "360a7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 0\n",
      "Image: 1\n",
      "Image: 2\n",
      "Image: 3\n",
      "Image: 4\n",
      "Image: 5\n",
      "Image: 6\n",
      "Image: 7\n",
      "Image: 8\n",
      "Image: 9\n",
      "Image: 10\n",
      "Image: 11\n",
      "Image: 12\n",
      "Image: 13\n",
      "Image: 14\n",
      "Image: 15\n",
      "Image: 16\n",
      "Image: 17\n",
      "Image: 18\n",
      "Image: 19\n",
      "Image: 20\n",
      "Image: 21\n",
      "Image: 22\n",
      "Image: 23\n",
      "Image: 24\n",
      "Image: 25\n",
      "Image: 26\n",
      "Image: 27\n",
      "Image: 28\n",
      "Image: 29\n"
     ]
    }
   ],
   "source": [
    "print(f'Input id emotion:')\n",
    "emotion_id = int(input())\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "for imgnum in range(number_images):\n",
    "    print(f'Image: {imgnum}')\n",
    "    \n",
    "    ret, image = cap.read()\n",
    "    idimg = str(uuid.uuid4())\n",
    "    \n",
    "    imgname = os.path.join(IMAGES_PATH_1, f'{idimg}.jpg')\n",
    "    cv2.imwrite(imgname, image)\n",
    "    \n",
    "    with mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
    "        image.flags.writeable = False\n",
    "        # Меняем цветовую гамму\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # Либа по посторойке координат на лице\n",
    "        results = face_mesh.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        # Возвращаем цвет обратно\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        face_landmarks = results.multi_face_landmarks[0]\n",
    "        \n",
    "        if face_landmarks:\n",
    "            mp_drawing.draw_landmarks(image=image,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles\n",
    "                .get_default_face_mesh_tesselation_style())\n",
    "        \n",
    "        dictMediapipeInArray(idimg, emotion_id, face_landmarks)\n",
    "\n",
    "    imgname = os.path.join(IMAGES_PATH_2, f'{idimg}.jpg')\n",
    "    cv2.imwrite(imgname, image)\n",
    "    \n",
    "    cv2.imshow('image', image)\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c82e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For static images:\n",
    "IMAGE_FILES = []\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=True,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5) as face_mesh:\n",
    "  for idx, file in enumerate(IMAGE_FILES):\n",
    "    image = cv2.imread(file)\n",
    "    # Convert the BGR image to RGB before processing.\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print and draw face mesh landmarks on the image.\n",
    "    if not results.multi_face_landmarks:\n",
    "      continue\n",
    "    annotated_image = image.copy()\n",
    "    for face_landmarks in results.multi_face_landmarks:\n",
    "      print('face_landmarks:', face_landmarks)\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_tesselation_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_contours_style())\n",
    "      mp_drawing.draw_landmarks(\n",
    "          image=annotated_image,\n",
    "          landmark_list=face_landmarks,\n",
    "          connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "          landmark_drawing_spec=None,\n",
    "          connection_drawing_spec=mp_drawing_styles\n",
    "          .get_default_face_mesh_iris_connections_style())\n",
    "    cv2.imwrite('/tmp/annotated_image' + str(idx) + '.png', annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ec89766d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name' 'id' ('x', 'y', 'z')]\n",
      " ['name' 0 (3, 0, 0)]]\n"
     ]
    }
   ],
   "source": [
    "f = np.array([[\"name\", 'id', ('x', 'y', 'z')]], dtype=object)\n",
    "f = np.append(f, [[\"name\", 0, (3, 0, 0)]], axis = 0)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7ab7db8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['x' 'y' 'z']\n",
      " [2 2 3]]\n"
     ]
    }
   ],
   "source": [
    "arr_cords = np.array([('x', 'y', 'z')], dtype=object)\n",
    "arr_cords = np.append(arr_cords, [(2, 2, 3)], axis = 0)\n",
    "print(arr_cords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0ffa6ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 4, 5])\n",
    "anp.delete(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06a1bf1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['name' 'id' list(['x', 'y', 'z'])]\n",
      " ['1' '3'\n",
      "  list([(1, 2, 3), (2, 3, 4), (3, 4, 5), (4, 5, 6), (5, 6, 7), (6, 7, 8)])]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [91], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m data\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(f)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdata\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "f = np.array([[\"name\", 'id', list(('x', 'y', 'z'))]], dtype=object)\n",
    "data = list()\n",
    "for i in range(6):\n",
    "    data.append((i+1, i+2, i+3))\n",
    "f = np.append(f, [['1', '3', data]], axis = 0)\n",
    "del data\n",
    "print(f)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f562d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
